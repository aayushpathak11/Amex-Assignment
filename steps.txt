step 1 - ingestion 
    - Loading and parsing the text from pdf using langchain pypdf loader
    - Since all the pdf have only textual information as seen after manually examining the data files, a text based parsing would be sufficient. No need to go for multi modal parsing of images/tables.
    - following langchain doc for this link - https://python.langchain.com/docs/integrations/document_loaders/pypdfloader/
    - after parsing, did some analysis on parsed text, to help in cleaning and pre processing
    - repeated the above steps for all the PDF Documents

step 2 - preprocessing
    - Cleaning each file's content using regex filter as identified by step 1
    - Now since this is a one time process, we can use this approach of analysing the data and then cleaning it using rule-based approach as that would help me in getting better results in later stages.
    - This rule based cleaning is important , and since it is one time ingestion process, we can apply this approach, as better and more cleaned the data better the results of later RAG pipeline.
    - applied chunking recursive character text splitter using langchain, tried different configurations of chunk sizes and overlap
    - https://python.langchain.com/docs/concepts/text_splitters/
    